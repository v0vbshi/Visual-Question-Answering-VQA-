{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4l4blCf4AjUF","executionInfo":{"status":"ok","timestamp":1667022145798,"user_tz":420,"elapsed":1125,"user":{"displayName":"Bowen Shi","userId":"09780949317012276340"}},"outputId":"6b2d4fee-4589-4459-da8e-c2b1af10de70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# !pip uninstall transformers\n","!pip install transformers==2.3.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyRVuEaH1cHB","executionInfo":{"status":"ok","timestamp":1667022153907,"user_tz":420,"elapsed":3630,"user":{"displayName":"Bowen Shi","userId":"09780949317012276340"}},"outputId":"0f2f00d5-f77e-400c-b349-e72d0530b15a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (2.23.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.25.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.0.53)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (1.21.6)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0) (0.1.97)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.0.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (0.6.0)\n","Requirement already satisfied: botocore<1.29.0,>=1.28.4 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.3.0) (1.28.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.4->boto3->transformers==2.3.0) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.29.0,>=1.28.4->boto3->transformers==2.3.0) (1.25.11)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.29.0,>=1.28.4->boto3->transformers==2.3.0) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0) (1.2.0)\n"]}]},{"cell_type":"markdown","source":["# Data_Load"],"metadata":{"id":"YJuZVLYo2ZnL"}},{"cell_type":"code","source":["import json\n","\n","from drive.MyDrive.NLP_Project.MMCoQA.retriever_utils import RetrieverDataset, GenPassageRepDataset\n","from transformers import BertTokenizer\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)"],"metadata":{"id":"J5zh4fPfdQco"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TKFp_ADQ1E2L","executionInfo":{"status":"ok","timestamp":1667022744171,"user_tz":420,"elapsed":48141,"user":{"displayName":"Bowen Shi","userId":"09780949317012276340"}},"outputId":"1f030233-6674-4899-bd71-e2b1ff4844f5"},"outputs":[{"output_type":"stream","name":"stdout","text":["590\n","<drive.MyDrive.NLP_Project.MMCoQA.retriever_utils.RetrieverDataset object at 0x7fbe4683a350>\n"]}],"source":["TRAIN_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/MMCoQA_train.txt' \n","DEV_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/MMCoQA_dev.txt'\n","TEST_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/MMCoQA_test.txt'\n","PASSAGES_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/multimodalqa_final_dataset_pipeline_camera_ready_MMQA_texts.jsonl'\n","TABLES_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/multimodalqa_final_dataset_pipeline_camera_ready_MMQA_tables.jsonl'\n","IMAGES_PATH = '/content/drive/MyDrive/NLP_Project/MMCoQA/multimodalqa_final_dataset_pipeline_camera_ready_MMQA_images.jsonl'\n","TOKENIZER = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","itemid_modalities=[]\n","\n","passages_dict={}\n","with open(PASSAGES_PATH,'r') as f:\n","    lines=f.readlines()\n","    for line in lines:\n","        line=json.loads(line.strip())\n","        passages_dict[line['id']]=line['text']\n","        itemid_modalities.append((line['id'], 'text'))\n","\n","tables_dict={}\n","with open(TABLES_PATH,'r') as f:\n","    lines=f.readlines()\n","    for line in lines:\n","        line=json.loads(line.strip())\n","        table_context = ''\n","        for row_data in line['table'][\"table_rows\"]:\n","            for cell in row_data:\n","                table_context=table_context+\" \"+cell['text']\n","        tables_dict[line['id']]=table_context\n","        itemid_modalities.append((line['id'], 'table'))\n","        \n","images_dict={}\n","with open(IMAGES_PATH,'r') as f:\n","    lines=f.readlines()\n","    for line in lines:\n","        line=json.loads(line.strip())\n","        images_dict[line['id']]=\"/content/drive/MyDrive/NLP_Project/MMCoQA/final_dataset_images/\"+line['path']\n","\n","\n","        itemid_modalities.append((line['id'], 'image'))\n","\n","image_answers_set=set()\n","with open(TRAIN_PATH, \"r\") as f:\n","    lines=f.readlines()\n","    for line in lines:\n","        image_answers_set.add(json.loads(line.strip())['answer'][0]['answer'])\n","\n","image_answers_str=''\n","for s in image_answers_set:\n","    image_answers_str=image_answers_str+\" \"+str(s)\n","\n","images_titles={}\n","with open(IMAGES_PATH,'r') as f:\n","    lines=f.readlines()\n","    for line in lines:\n","        line=json.loads(line.strip())\n","        images_titles[line['id']]=line['title']+\" \"+image_answers_str\n","\n","# only_positive_passage=True -> gives the evidence for the question as well\n","# is_pretraining -> gives the question text and answer text too\n","\n","dataset = RetrieverDataset(\n","    TEST_PATH, TOKENIZER, False, 1, \n","    only_positive_passage=True, \n","    given_query=True, given_passage=True, is_pretraining=False,\n","    passages_dict=passages_dict, tables_dict=tables_dict, images_dict=images_dict)\n","\n","idx_id_list = []\n","\n","kb = GenPassageRepDataset(\n","    TEST_PATH, TOKENIZER, False,\n","    passages_dict=passages_dict, tables_dict=tables_dict, images_dict=images_dict, idx_id_list=itemid_modalities\n",")"]},{"cell_type":"code","source":["# print(len(passages_dict), len(images_dict), len(tables_dict))\n","print(len(dataset))\n","print(dataset[2])\n","# print(dataset[2])\n","# print(dataset[2])\n","# print(dataset[2]['query_input_ids'].shape)\n","# print(dataset[2]['passage_input_ids'].shape)\n","print(len(kb))\n","# print(kb[0])\n","# print(kb[-1])\n","# print(passages_dict['4fc4bb584aceca85d7afab22bbb20be9'])"],"metadata":{"id":"c-JeG9ig16QF","colab":{"base_uri":"https://localhost:8080/","height":415},"executionInfo":{"status":"error","timestamp":1667026373891,"user_tz":420,"elapsed":255,"user":{"displayName":"Bowen Shi","userId":"09780949317012276340"}},"outputId":"ee633062-1961-4473-a536-8f678fe0ca48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["590\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-6f5608938ea3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print(len(passages_dict), len(images_dict), len(tables_dict))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(dataset[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(dataset[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NLP_Project/MMCoQA/retriever_utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/NLP_Project/MMCoQA/retriever_utils.py\u001b[0m in \u001b[0;36m_image_transform\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# IndexError: too many indices for array, grayscale images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/NLP_Project/MMCoQA/final_dataset_images/40e1ad6cdf23cdc380c9e636718a1105.jpg'"]}]},{"cell_type":"code","source":["MODEL_CLASSES = {\n","    'bert': (BertConfig, BertForRetrieverOnlyPositivePassage, BertTokenizer),\n","}\n","cache_dir = './huggingface_cache/bert-base-uncased'\n","config_class, model_class, tokenizer_class = MODEL_CLASSES['bert']\n","config = config_class.from_pretrained('bert-base-uncased',\n","                                      cache_dir=cache_dir)\n","config.proj_size = PROJ_SIZE\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model_class.from_pretrained('bert-base-uncased',\n","                                    from_tf=False,\n","                                    config=config,\n","                                    cache_dir=cache_dir,\n","                                    proj_size=PROJ_SIZE)\n","\n","def to_list(tensor):\n","    return tensor.detach().cpu().tolist()\n","\n","def gen_passage_rep(dataset, model):\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)\n","\n","    eval_batch_size = 128\n","    eval_sampler = SequentialSampler(dataset)\n","    eval_dataloader = DataLoader(\n","        dataset, sampler=eval_sampler, batch_size=eval_batch_size, num_workers=NUM_WORKERS)\n","\n","    logger.info(\"***** Gem passage rep *****\")\n","    logger.info(\"  Num examples = %d\", len(dataset))\n","    logger.info(\"  Batch size = %d\", eval_batch_size)\n","    fout = open(GEN_PASSAGE_REP_OUTPUT, 'w')\n","    passage_ids = []\n","    passage_reps_list = []\n","    print(\"start gen_passage_rep\")\n","    # print(data)\n","    # for i, batch in enumerate(tqdm(eval_dataloader, desc=\"Evaluating\")):\n","    for batch in dataset:\n","        model.eval()\n","        example_ids = np.asarray(\n","            batch['example_id']).reshape(-1).tolist()\n","        passage_ids.extend(example_ids)\n","        batch = {k: v for k, v in batch.items() if k != 'example_id'}\n","        with torch.no_grad():\n","            inputs = {}\n","            inputs['passage_input_ids'] = [batch['passage_input_ids']]\n","            inputs['passage_attention_mask'] = batch['passage_attention_mask']\n","            inputs['passage_token_type_ids'] = batch['passage_token_type_ids']\n","            inputs['question_type'] = batch['question_type']\n","            # inputs['image_input'] = batch['image_input'].type(torch.FloatTensor).to(device)\n","            inputs['image_input'] = torch.from_numpy(batch['image_input'])\n","            print(inputs)\n","            outputs = model(**inputs)\n","            passage_reps = outputs[0]\n","            passage_reps_list.extend(to_list(passage_reps))\n","\n","        # with open(args.gen_passage_rep_output, 'w') as fout:\n","        for example_id, passage_rep in zip(example_ids, to_list(passage_reps)):\n","            fout.write(json.dumps({'id': example_id, 'rep': passage_rep}) + '\\n')\n","    fout.close()\n","    print(\"end gen_passage_rep_output\")\n","    return passage_ids, passage_reps_list\n","\n","passage_ids, passage_reps = gen_passage_rep(kb, model)\n","print(passage_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":290},"id":"fAUvHL4waNXy","executionInfo":{"status":"error","timestamp":1667026194383,"user_tz":420,"elapsed":155,"user":{"displayName":"Bowen Shi","userId":"09780949317012276340"}},"outputId":"93804700-640f-42d4-c66a-6daa3b1619e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-021acef448f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'example_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'qid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'RetrieverDataset' object has no attribute 'items'"]}]}]}